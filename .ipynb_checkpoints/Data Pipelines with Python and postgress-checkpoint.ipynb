{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b9818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "# Pipeline\n",
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6edc10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "default_args = {\n",
    "    'owner': 'Safaricom',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2023, 4, 10),\n",
    "    'email': ['newton.kipngeno@student.moringaschool.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 3,\n",
    "    'retry_delay': timedelta(minutes=5)\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'equipment_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='Pipeline for equipment data',\n",
    "    schedule_interval=timedelta(days=1),\n",
    ")\n",
    "\n",
    "# Extract data\n",
    "def extract_csv(filename):\n",
    "  data = pd.read_csv(filename)\n",
    "  return data\n",
    "\n",
    "# transform\n",
    "def transform_data(dataframe):\n",
    "  # Remove duplicates\n",
    "  dataframe = dataframe.drop_duplicates()\n",
    "  # remove nulls\n",
    "  dataframe = dataframe.dropna()\n",
    "  return dataframe\n",
    "\n",
    "def merge_equiment_reading(df1, df2):\n",
    "    inner_join_df = pd.merge(df1,df2)\n",
    "    return inner_join_df\n",
    "\n",
    "#load equipment readings data to postgress\n",
    "def load_equipment_readings(df):\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    database=\"data_engineering\",\n",
    "    user=\"newton\",\n",
    "    password=\"newton123\"\n",
    ")\n",
    "    cur = conn.cursor()\n",
    "    #Create table if it does not exist\n",
    "    try:\n",
    "        sql = \"CREATE TABLE IF NOT EXISTS EQUIPMENT_READINGS (ID SERIAL PRIMARY KEY, equipment_id integer, date text, time text, network_sensor_reading text, equipment_sensor_reading text)\"\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "    except:\n",
    "        return \"Error creating table\"\n",
    "    #Insert data\n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            cur.execute(\"INSERT INTO EQUIPMENT_READINGS (equipment_id, date, time, network_sensor_reading, equipment_sensor_reading) VALUES(%s, %s, %s, %s, %s)\", row['equipment_id'], row['date'], row['time'], row['network_sensor_reading'], row['equipment_sensor_reading'])\n",
    "    except:\n",
    "        return \"Error inserting data\"\n",
    "    conn.close()\n",
    "    \n",
    "#load equipment maintenance data\n",
    "def load_equipment_maintenance(df):\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    database=\"data_engineering\",\n",
    "    user=\"newton\",\n",
    "    password=\"newton123\"\n",
    ")\n",
    "    cur = conn.cursor()\n",
    "    #Create table if it does not exist\n",
    "    try:\n",
    "        sql = \"CREATE TABLE IF NOT EXISTS EQUIPMENT_MAINTENANCE (ID SERIAL PRIMARY KEY, equipment_id integer, date text, time text, maintenance_type text)\"\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "    except:\n",
    "        return \"Error creating table\"\n",
    "    #Insert data\n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            cur.execute(\"INSERT INTO EQUIPMENT_MAINTENANCE (equipment_id, date, time, maintenance_type) VALUES(%s, %s, %s, %s)\", row['equipment_id'], row['date'], row['time'], row['maintenance_type'])\n",
    "    except:\n",
    "        return \"Error inserting data\"\n",
    "    conn.close()\n",
    "    \n",
    "extract = PythonOperator(\n",
    "    task_id='extract_csv',\n",
    "    python_callable=extract_csv,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "transform = PythonOperator(\n",
    "    task_id='transform_data',\n",
    "    python_callable=transform_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "merge = PythonOperator(\n",
    "    task_id='merge_equiment_reading',\n",
    "    python_callable=merge_equiment_reading,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "load1 = PythonOperator(\n",
    "    task_id='load_equipment_readings',\n",
    "    python_callable=load_equipment_readings,\n",
    "    dag=dag,\n",
    ")\n",
    "load2 = PythonOperator(\n",
    "    task_id='load_equipment_maintenance',\n",
    "    python_callable=load_equipment_maintenance,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "extract >> transform >> merge >> load1 >> load2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
